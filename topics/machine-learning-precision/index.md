# Machine learning precision

Precision is a machine learning performance metric. It is particularly used in classification tasks.

Precision is a measure of how many of the predicted positive instances are actually positive. It represents the proportion of true positive predictions (correctly predicted positive class) over the total positive predictions (both true positives and false positives). Precision focuses on the accuracy of positive predictions and is particularly useful when the cost of false positives is high.

Formula:

  * $Precision = (True Positives) / (True Positives + False Positives)$

High precision indicates that when the model predicts a positive instance, it is likely to be correct. However, a high precision may come at the cost of increased false negatives, as the model may be more conservative in making positive predictions.
